# Code Sandbox MCP Server

The Code Sandbox MCP Server is a secure, STDIO-based Model Context Protocol (MCP) Server, allowing AI assistants and LLM applications to safely execute code snippets.

**How It Works:**

1. Starts a container session (podman, docker, etc.) and ensures the session is open.
2. Writes the `code` to a temporary file on the host.
3. Copies this temporary file into the container at the configured `workdir`.
4. Executes the language-specific commands to run the code, e.g. python `python3 -u code.py` or javascript `node -u code.js`
5. Captures the output and error streams from the container.
6. Returns the output and error streams to the client.

## Key Features

üõ°Ô∏è **Secure Execution**: Run untrusted code generated by LLMs in a fully isolated container. The server enforces resource limits (CPU, memory, time) and network isolation, preventing malicious or runaway code from affecting the host system.

‚ÜîÔ∏è **STDIO Transport**: Designed for simplicity and efficiency, the server communicates over standard input/output (STDIO). 

üíª **Multi-Language Support**: Currently supports Python and JavaScript out-of-the-box, with a flexible architecture to easily add more languages.

## Available Tools

The server currently exposes the following tools:

### `run_python_code`

Executes a snippet of Python code in a secure, isolated sandbox.

**Parameters:**
*   `code` (string, required): The Python code to execute.

### `run_js_code`

Executes a snippet of JavaScript (Node.js) code in a secure, isolated sandbox.

**Parameters:**
*   `code` (string, required): The JavaScript code to execute.

## Installation

The MCP server is included with the main `llm-sandbox` package. Ensure you have a container backend like Docker installed.

```bash
pip install 'code-sandbox-mcp'
```

## Getting Started: Usage with an MCP Client

To use the Code Sandbox MCP server, you need to add it to your MCP client's configuration file (e.g., in your AI assistant's settings). The server is designed to be launched on-demand by the client.

Add the following to your `mcpServers` configuration:

```json
{
  "mcpServers": {
    "code-sandbox": {
      "command": "code-sandbox-mcp",
    }
  }
}
```

## Testing

To run the test suite for `llm-sandbox` and its components, clone the repository and run:

```bash
# You may need to install development dependencies first
pip install -e ".[dev]"

# Run the tests
pytest
```

## License

LLM Sandbox is open source software licensed under the [MIT License](https://github.com/vndee/llm-sandbox/blob/main/LICENSE).